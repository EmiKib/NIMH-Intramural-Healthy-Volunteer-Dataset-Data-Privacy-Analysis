{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycanon\n",
    "import time\n",
    "\n",
    "data = pd.read_csv(\"data/adult.csv\")  # 32561 rows\n",
    "data.columns = data.columns.str.strip()\n",
    "cols = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "]\n",
    "\n",
    "\n",
    "combined_column = data[['sex', 'race', 'relationship', 'workclass']].astype(str).agg('-'.join, axis=1)\n",
    "unique_rows_count = combined_column.nunique()\n",
    "unique_rows_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I wanna make a function take takes in an arbitrarity numbers of column and then calculate which columns together has the least unique rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: education, Impact on Unique Rows: 67\n",
      "Feature: marital-status, Impact on Unique Rows: 68\n",
      "Feature: race, Impact on Unique Rows: 65\n",
      "Original Unique Rows Count: 68\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_unique_rows_impact(dataframe):\n",
    "    # Calculate the number of unique rows in the original dataframe\n",
    "    value_counts = dataframe.value_counts()\n",
    "    original_unique_count = len(value_counts[value_counts == 1])\n",
    "\n",
    "    attributes = dataframe.columns\n",
    "    results = {}\n",
    "\n",
    "    for attr in attributes:\n",
    "        # Drop the column and calculate unique rows again\n",
    "        subset_df = dataframe.drop(columns=[attr])\n",
    "        value_counts_after_removal = subset_df.value_counts()\n",
    "        unique_count_after_removal = len(value_counts_after_removal[value_counts_after_removal == 1])\n",
    "        impact = original_unique_count - unique_count_after_removal\n",
    "        results[attr] = impact\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Analyze impact of each feature\n",
    "unique_row_impact = analyze_unique_rows_impact(df)\n",
    "\n",
    "# Display the impact of each feature on unique rows\n",
    "for attr, impact in unique_row_impact.items():\n",
    "    print(f\"Feature: {attr}, Impact on Unique Rows: {impact}\")\n",
    "\n",
    "# Print original unique row count\n",
    "value_counts = df.value_counts()\n",
    "original_unique_count = len(value_counts[value_counts == 1])\n",
    "print(f\"Original Unique Rows Count: {original_unique_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: education, Impact on Unique Rows: 67\n",
      "Feature: marital-status, Impact on Unique Rows: 68\n",
      "Feature: race, Impact on Unique Rows: 65\n",
      "Original Unique Rows Count: 68\n",
      "\n",
      "Feature: education, Value counts for rows that lost uniqueness:\n",
      "education\n",
      " Doctorate      9\n",
      " 1st-4th        7\n",
      " 5th-6th        6\n",
      " 7th-8th        6\n",
      " Assoc-acdm     6\n",
      " Assoc-voc      5\n",
      " Prof-school    5\n",
      " Preschool      5\n",
      " 11th           4\n",
      " Bachelors      4\n",
      " 9th            3\n",
      " 10th           3\n",
      " 12th           2\n",
      " Masters        2\n",
      " HS-grad        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature: marital-status, Value counts for rows that lost uniqueness:\n",
      "marital-status\n",
      " Married-spouse-absent    18\n",
      " Divorced                 14\n",
      " Separated                12\n",
      " Widowed                   9\n",
      " Never-married             8\n",
      " Married-civ-spouse        5\n",
      " Married-AF-spouse         2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature: race, Value counts for rows that lost uniqueness:\n",
      "race\n",
      " Amer-Indian-Eskimo    19\n",
      " Other                 19\n",
      " Black                 15\n",
      " Asian-Pac-Islander    13\n",
      " White                  2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_unique_rows_impact(dataframe):\n",
    "    # Calculate the number of unique rows in the original dataframe\n",
    "    value_counts = dataframe.value_counts()\n",
    "    original_unique_rows = value_counts[value_counts == 1].index\n",
    "\n",
    "    attributes = dataframe.columns\n",
    "    results = {}\n",
    "    unique_row_indices = {}\n",
    "\n",
    "    for attr in attributes:\n",
    "        # Drop the column and calculate unique rows again\n",
    "        subset_df = dataframe.drop(columns=[attr])\n",
    "        value_counts_after_removal = subset_df.value_counts()\n",
    "        unique_rows_after_removal = value_counts_after_removal[value_counts_after_removal == 1].index\n",
    "\n",
    "        impact = len(original_unique_rows) - len(unique_rows_after_removal)\n",
    "        results[attr] = impact\n",
    "\n",
    "        # Identify the rows that lost their uniqueness\n",
    "        lost_uniqueness_rows = set(original_unique_rows) - set(unique_rows_after_removal)\n",
    "        unique_row_indices[attr] = lost_uniqueness_rows\n",
    "\n",
    "    return results, unique_row_indices\n",
    "\n",
    "\n",
    "\n",
    "# Analyze impact of each feature\n",
    "unique_row_impact, unique_row_indices = analyze_unique_rows_impact(df)\n",
    "\n",
    "# Display the impact of each feature on unique rows\n",
    "for attr, impact in unique_row_impact.items():\n",
    "    print(f\"Feature: {attr}, Impact on Unique Rows: {impact}\")\n",
    "\n",
    "# Print original unique row count\n",
    "value_counts = df.value_counts()\n",
    "original_unique_count = len(value_counts[value_counts == 1])\n",
    "print(f\"Original Unique Rows Count: {original_unique_count}\")\n",
    "\n",
    "# Display the value counts for the specific rows that lost uniqueness\n",
    "for attr, rows in unique_row_indices.items():\n",
    "    print(f\"\\nFeature: {attr}, Value counts for rows that lost uniqueness:\")\n",
    "    filtered_df = pd.DataFrame(list(rows), columns=df.columns)\n",
    "    print(filtered_df[attr].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       " HS-grad         10501\n",
       " Some-college     7291\n",
       " Bachelors        5355\n",
       " Masters          1723\n",
       " Assoc-voc        1382\n",
       " 11th             1175\n",
       " Assoc-acdm       1067\n",
       " 10th              933\n",
       " 7th-8th           646\n",
       " Prof-school       576\n",
       " 9th               514\n",
       " 12th              433\n",
       " Doctorate         413\n",
       " 5th-6th           333\n",
       " 1st-4th           168\n",
       " Preschool          51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: education, Impact on Unique Rows: 67\n",
      "Feature: marital-status, Impact on Unique Rows: 68\n",
      "Feature: race, Impact on Unique Rows: 65\n",
      "Original Unique Rows Count: 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     education          marital-status                 race\n",
       "0    Doctorate      Married-civ-spouse   Amer-Indian-Eskimo\n",
       "3    Doctorate           Never-married                Black\n",
       "6    Doctorate                Divorced                Black\n",
       "8    Doctorate           Never-married   Amer-Indian-Eskimo\n",
       "14   Doctorate   Married-spouse-absent   Amer-Indian-Eskimo\n",
       "15   Doctorate   Married-spouse-absent   Asian-Pac-Islander\n",
       "29   Doctorate                Divorced                Other\n",
       "50   Doctorate               Separated                Black\n",
       "53   Doctorate      Married-civ-spouse                Other"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_unique_rows_impact(dataframe):\n",
    "    # Calculate the number of unique rows in the original dataframe\n",
    "    value_counts = dataframe.value_counts()\n",
    "    original_unique_rows = value_counts[value_counts == 1].index\n",
    "\n",
    "    attributes = dataframe.columns\n",
    "    results = {}\n",
    "    unique_row_indices = {}\n",
    "\n",
    "    for attr in attributes:\n",
    "        # Drop the column and calculate unique rows again\n",
    "        subset_df = dataframe.drop(columns=[attr])\n",
    "        value_counts_after_removal = subset_df.value_counts()\n",
    "        unique_rows_after_removal = value_counts_after_removal[value_counts_after_removal == 1].index\n",
    "\n",
    "        impact = len(original_unique_rows) - len(unique_rows_after_removal)\n",
    "        results[attr] = impact\n",
    "\n",
    "        # Identify the rows that lost their uniqueness\n",
    "        lost_uniqueness_rows = set(original_unique_rows) - set(unique_rows_after_removal)\n",
    "        unique_row_indices[attr] = lost_uniqueness_rows\n",
    "\n",
    "    return results, unique_row_indices\n",
    "\n",
    "\n",
    "# Analyze impact of each feature\n",
    "unique_row_impact, unique_row_indices = analyze_unique_rows_impact(df)\n",
    "\n",
    "# Display the impact of each feature on unique rows\n",
    "for attr, impact in unique_row_impact.items():\n",
    "    print(f\"Feature: {attr}, Impact on Unique Rows: {impact}\")\n",
    "\n",
    "# Print original unique row count\n",
    "value_counts = df.value_counts()\n",
    "original_unique_count = len(value_counts[value_counts == 1])\n",
    "print(f\"Original Unique Rows Count: {original_unique_count}\")\n",
    "\n",
    "# Create DataFrames for rows that lost uniqueness\n",
    "e = pd.DataFrame(list(unique_row_indices['education']), columns=df.columns)\n",
    "m = pd.DataFrame(list(unique_row_indices['marital-status']), columns=df.columns)\n",
    "r = pd.DataFrame(list(unique_row_indices['race']), columns=df.columns)\n",
    "\n",
    "e[e['education']==' Doctorate']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       " HS-grad         10501\n",
       " Some-college     7291\n",
       " Bachelors        5355\n",
       " Masters          1723\n",
       " Assoc-voc        1382\n",
       " 11th             1175\n",
       " Assoc-acdm       1067\n",
       " 10th              933\n",
       " 7th-8th           646\n",
       " Prof-school       576\n",
       " 9th               514\n",
       " 12th              433\n",
       " Doctorate         413\n",
       " 5th-6th           333\n",
       " 1st-4th           168\n",
       " Preschool          51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique combinations: 220\n",
      "max: 288\n"
     ]
    }
   ],
   "source": [
    "unique_combinations = data[['sex', 'education','workclass']].drop_duplicates()\n",
    "# Count the number of unique combinations\n",
    "num_unique_combinations = unique_combinations.shape[0]\n",
    "print(f\"Number of unique combinations: {num_unique_combinations}\")\n",
    "print('max:',data['sex'].nunique() * data['education'].nunique()*data['workclass'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>PrivacyFactor</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>0.998596</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.998672</td>\n",
       "      <td>753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>85</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>87</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>88</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>90</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  PrivacyFactor  Values\n",
       "0    17       0.997468   395.0\n",
       "1    18       0.998182   550.0\n",
       "2    19       0.998596   712.0\n",
       "3    20       0.998672   753.0\n",
       "4    21       0.998611   720.0\n",
       "..  ...            ...     ...\n",
       "68   85       0.666667     3.0\n",
       "69   86       0.000000     1.0\n",
       "70   87       0.000000     1.0\n",
       "71   88       0.666667     3.0\n",
       "72   90       0.976744    43.0\n",
       "\n",
       "[73 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "grouped = data.groupby(['age']).size().reset_index(name='count')\n",
    "\n",
    "# Define a function to calculate the privacy metrics\n",
    "def calculate_privacy_profile(group):\n",
    "    total = group['count'].sum()\n",
    "    values = group['count']\n",
    "    categories = len(values)\n",
    "    \n",
    "    priv_factor = sum(1 - (1 / freq) for freq in values) / categories\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"PrivacyFactor\": priv_factor,\n",
    "        \"Values\": total,\n",
    "    })\n",
    "\n",
    "# Apply the function to the grouped data\n",
    "privacy_profile = grouped.groupby(['age']).apply(calculate_privacy_profile).reset_index()\n",
    "\n",
    "# Print the resulting privacy profile\n",
    "privacy_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.492058687257062"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(1/math.log(1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "36    898\n",
       "31    888\n",
       "34    886\n",
       "23    877\n",
       "35    876\n",
       "     ... \n",
       "83      6\n",
       "88      3\n",
       "85      3\n",
       "86      1\n",
       "87      1\n",
       "Name: count, Length: 73, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>PrivacyFactor</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>0.998596</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.998672</td>\n",
       "      <td>753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>85</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>87</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>88</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>90</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  PrivacyFactor  Values\n",
       "0    17       0.997468   395.0\n",
       "1    18       0.998182   550.0\n",
       "2    19       0.998596   712.0\n",
       "3    20       0.998672   753.0\n",
       "4    21       0.998611   720.0\n",
       "..  ...            ...     ...\n",
       "68   85       0.666667     3.0\n",
       "69   86       0.000000     1.0\n",
       "70   87       0.000000     1.0\n",
       "71   88       0.666667     3.0\n",
       "72   90       0.976744    43.0\n",
       "\n",
       "[73 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Group by 'age' and count occurrences\n",
    "grouped = data.groupby(['age']).size().reset_index(name='count')\n",
    "\n",
    "# Define a function to calculate the privacy metrics\n",
    "def calculate_privacy_profile(group):\n",
    "    total = group['count'].sum()\n",
    "    values = group['count']\n",
    "    categories = len(values)\n",
    "    \n",
    "    # Calculate Privacy Factor\n",
    "    priv_factor = sum(1 - (1 / freq) for freq in values) / categories\n",
    "    \n",
    "    return pd.Series({\n",
    "        \"PrivacyFactor\": priv_factor,\n",
    "        \"Values\": total,\n",
    "    })\n",
    "\n",
    "# Apply the function to the grouped data\n",
    "privacy_profile = grouped.groupby(['age']).apply(calculate_privacy_profile).reset_index()\n",
    "\n",
    "# Print the resulting privacy profile\n",
    "privacy_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Privacy Factor: 421.2372230568297\n"
     ]
    }
   ],
   "source": [
    "def cumulative_privacy_factor(fields, privacy_profile_df):\n",
    "    factor = 1\n",
    "    for field in fields:\n",
    "        if field in privacy_profile_df.index:\n",
    "            factor *= privacy_profile_df.loc[field, 'PrivacyFactor']\n",
    "    return factor\n",
    "\n",
    "# Example usage\n",
    "requested_fields = ['sex', 'education','race','salary-class', 'occupation']\n",
    "cumulative_factor = cumulative_privacy_factor(requested_fields, privacy_profile_df)\n",
    "print(f\"Cumulative Privacy Factor: {cumulative_factor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PrivacyFactor</th>\n",
       "      <th>Shannons</th>\n",
       "      <th>Harts</th>\n",
       "      <th>Values</th>\n",
       "      <th>Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.999931</td>\n",
       "      <td>13.903122</td>\n",
       "      <td>4.185257</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary-class</th>\n",
       "      <td>0.999916</td>\n",
       "      <td>13.765107</td>\n",
       "      <td>4.143710</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.999610</td>\n",
       "      <td>11.886329</td>\n",
       "      <td>3.578142</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.998355</td>\n",
       "      <td>10.551341</td>\n",
       "      <td>3.176270</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.997306</td>\n",
       "      <td>9.767929</td>\n",
       "      <td>2.940440</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0.997306</td>\n",
       "      <td>9.767929</td>\n",
       "      <td>2.940440</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0.993109</td>\n",
       "      <td>10.365527</td>\n",
       "      <td>3.120335</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0.991639</td>\n",
       "      <td>10.255226</td>\n",
       "      <td>3.087131</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0.975727</td>\n",
       "      <td>9.404759</td>\n",
       "      <td>2.831115</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.952033</td>\n",
       "      <td>7.689832</td>\n",
       "      <td>2.314870</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0.948611</td>\n",
       "      <td>5.717827</td>\n",
       "      <td>1.721237</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.865268</td>\n",
       "      <td>5.190036</td>\n",
       "      <td>1.562357</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.779374</td>\n",
       "      <td>3.255042</td>\n",
       "      <td>0.979865</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.701402</td>\n",
       "      <td>2.848192</td>\n",
       "      <td>0.857391</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>0.170447</td>\n",
       "      <td>0.391272</td>\n",
       "      <td>0.117785</td>\n",
       "      <td>32561.0</td>\n",
       "      <td>21648.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PrivacyFactor   Shannons     Harts   Values  Categories\n",
       "sex                  0.999931  13.903122  4.185257  32561.0         2.0\n",
       "salary-class         0.999916  13.765107  4.143710  32561.0         2.0\n",
       "relationship         0.999610  11.886329  3.578142  32561.0         6.0\n",
       "race                 0.998355  10.551341  3.176270  32561.0         5.0\n",
       "education            0.997306   9.767929  2.940440  32561.0        16.0\n",
       "education-num        0.997306   9.767929  2.940440  32561.0        16.0\n",
       "marital-status       0.993109  10.365527  3.120335  32561.0         7.0\n",
       "occupation           0.991639  10.255226  3.087131  32561.0        15.0\n",
       "workclass            0.975727   9.404759  2.831115  32561.0         9.0\n",
       "age                  0.952033   7.689832  2.314870  32561.0        73.0\n",
       "native-country       0.948611   5.717827  1.721237  32561.0        42.0\n",
       "hours-per-week       0.865268   5.190036  1.562357  32561.0        94.0\n",
       "capital-gain         0.779374   3.255042  0.979865  32561.0       119.0\n",
       "capital-loss         0.701402   2.848192  0.857391  32561.0        92.0\n",
       "fnlwgt               0.170447   0.391272  0.117785  32561.0     21648.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_privacy_profile(df):\n",
    "    privacy_profiles = {}\n",
    "    \n",
    "    for field_name in df.columns:\n",
    "        field_data = df[field_name]\n",
    "        total = len(field_data)\n",
    "        value_counts = field_data.value_counts()\n",
    "        values = value_counts.values\n",
    "        categories = len(values)\n",
    "        \n",
    "        # Calculate Privacy Factor\n",
    "        priv_factor = np.sum([1 - (1 /freq) for freq in values]) / categories\n",
    "        \n",
    "        # Calculate Shannon Entropy\n",
    "        shannon = np.sum([np.log2(freq) for freq in values]) / categories\n",
    "        \n",
    "        # Calculate Hartley Entropy\n",
    "        hart = np.sum([np.log10(freq) for freq in values]) / categories\n",
    "        \n",
    "        # Store the results\n",
    "        privacy_profiles[field_name] = {\n",
    "            \"PrivacyFactor\": priv_factor,\n",
    "            \"Shannons\": shannon,\n",
    "            \"Harts\": hart,\n",
    "            \"Values\": total,\n",
    "            \"Categories\": categories\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(privacy_profiles).T\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    " \n",
    "    \n",
    "    # Calculate privacy profile\n",
    "    privacy_profile_df = calculate_privacy_profile(data)\n",
    "    \n",
    "    # Print the resulting privacy profile\n",
    "\n",
    "privacy_profile_df = privacy_profile_df.sort_values(by=\"PrivacyFactor\", ascending=False)\n",
    "privacy_profile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emiliekibsgaard/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Normalized Entropy</th>\n",
       "      <th>Unique Rows Excluding Column</th>\n",
       "      <th>Contribution Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>occupation</td>\n",
       "      <td>15</td>\n",
       "      <td>3.516903</td>\n",
       "      <td>0.234460</td>\n",
       "      <td>3367</td>\n",
       "      <td>0.015668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>education</td>\n",
       "      <td>16</td>\n",
       "      <td>2.931351</td>\n",
       "      <td>0.183209</td>\n",
       "      <td>3024</td>\n",
       "      <td>0.015510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>8</td>\n",
       "      <td>2.439501</td>\n",
       "      <td>0.304938</td>\n",
       "      <td>3961</td>\n",
       "      <td>0.004927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>workclass</td>\n",
       "      <td>9</td>\n",
       "      <td>1.647977</td>\n",
       "      <td>0.183109</td>\n",
       "      <td>5154</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6</td>\n",
       "      <td>2.154424</td>\n",
       "      <td>0.359071</td>\n",
       "      <td>5625</td>\n",
       "      <td>0.002298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital-status</td>\n",
       "      <td>7</td>\n",
       "      <td>1.833649</td>\n",
       "      <td>0.261950</td>\n",
       "      <td>5682</td>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>race</td>\n",
       "      <td>5</td>\n",
       "      <td>0.798741</td>\n",
       "      <td>0.159748</td>\n",
       "      <td>5587</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "      <td>0.915736</td>\n",
       "      <td>0.457868</td>\n",
       "      <td>6625</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Column  Unique Values   Entropy  Normalized Entropy  \\\n",
       "4      occupation             15  3.516903            0.234460   \n",
       "7       education             16  2.931351            0.183209   \n",
       "5             age              8  2.439501            0.304938   \n",
       "6       workclass              9  1.647977            0.183109   \n",
       "3    relationship              6  2.154424            0.359071   \n",
       "2  marital-status              7  1.833649            0.261950   \n",
       "1            race              5  0.798741            0.159748   \n",
       "0             sex              2  0.915736            0.457868   \n",
       "\n",
       "   Unique Rows Excluding Column  Contribution Score  \n",
       "4                          3367            0.015668  \n",
       "7                          3024            0.015510  \n",
       "5                          3961            0.004927  \n",
       "6                          5154            0.002878  \n",
       "3                          5625            0.002298  \n",
       "2                          5682            0.002259  \n",
       "1                          5587            0.000715  \n",
       "0                          6625            0.000276  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Total number of rows (adjusted for the subset of data)\n",
    "def get_total_rows(df):\n",
    "    return len(df)\n",
    "\n",
    "def calculate_entropy(column):\n",
    "    # Calculate entropy for the column\n",
    "    value_counts = column.value_counts(normalize=True)\n",
    "    return entropy(value_counts, base=2)\n",
    "\n",
    "def normalize_entropy(entropy_value, unique_values_count):\n",
    "    return entropy_value / unique_values_count\n",
    "\n",
    "def count_unique_rows(df):\n",
    "    # Count occurrences of each row\n",
    "    value_counts = df.value_counts()\n",
    "    # Count rows that only occur once\n",
    "    unique_rows_count = len(value_counts[value_counts == 1])\n",
    "    return unique_rows_count\n",
    "\n",
    "def calculate_unique_rows_excluding_column(df, column_name):\n",
    "    # Exclude the specified column\n",
    "    df_reduced = df.drop(columns=[column_name])\n",
    "    # Calculate unique rows in the reduced DataFrame\n",
    "    return count_unique_rows(df_reduced)\n",
    "\n",
    "def calculate_contribution_score(df, column_name):\n",
    "    column = df[column_name]\n",
    "    unique_values_count = column.nunique()\n",
    "    unique_rows_count_excluding_column = calculate_unique_rows_excluding_column(df, column_name)\n",
    "    entropy_value = calculate_entropy(column)\n",
    "    normalized_entropy_value = normalize_entropy(entropy_value, unique_values_count)\n",
    "    \n",
    "    # Contribution score\n",
    "    contribution_score = ((entropy_value * unique_values_count) / unique_rows_count_excluding_column) \n",
    "    return entropy_value, unique_values_count, unique_rows_count_excluding_column, normalized_entropy_value, contribution_score\n",
    "\n",
    "# Select specific columns\n",
    "selected_columns = ['sex', 'race', 'marital-status','relationship','occupation','age','workclass','education']\n",
    "data_subset = data[selected_columns]\n",
    "data_subset['age'] = (data_subset['age'] // 10 * 10) + (data['age'] % 10 >= 5) * 10\n",
    "\n",
    "# Total number of rows for the subset\n",
    "total_rows = get_total_rows(data_subset)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for col in selected_columns:\n",
    "    entropy_value, unique_values, unique_rows_excluding_column, normalized_entropy_value, contribution_score = calculate_contribution_score(data_subset, col)\n",
    "    results.append({\n",
    "        'Column': col,\n",
    "        'Unique Values': unique_values,\n",
    "        'Entropy': entropy_value,\n",
    "        'Normalized Entropy': normalized_entropy_value,\n",
    "        'Unique Rows Excluding Column': unique_rows_excluding_column,\n",
    "        'Contribution Score': contribution_score\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better readability\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort results by Contribution Score\n",
    "results_df = results_df.sort_values(by='Contribution Score', ascending=False)\n",
    "\n",
    "print(len(data))\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Husband           0.405178\n",
       " Not-in-family     0.255060\n",
       " Own-child         0.155646\n",
       " Unmarried         0.105832\n",
       " Wife              0.048156\n",
       " Other-relative    0.030128\n",
       "Name: relationship, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['relationship'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Married-civ-spouse       0.459937\n",
       " Never-married            0.328092\n",
       " Divorced                 0.136452\n",
       " Separated                0.031479\n",
       " Widowed                  0.030497\n",
       " Married-spouse-absent    0.012837\n",
       " Married-AF-spouse        0.000706\n",
       "Name: marital-status, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['marital-status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy measures the amount of uncertainty or disorder in a distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Shannon Entropy</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Unique Rows After Excluding Column</th>\n",
       "      <th>Contribution Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>5.683324</td>\n",
       "      <td>73</td>\n",
       "      <td>4672</td>\n",
       "      <td>0.088802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>occupation</td>\n",
       "      <td>3.516903</td>\n",
       "      <td>15</td>\n",
       "      <td>10411</td>\n",
       "      <td>0.005067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>education</td>\n",
       "      <td>2.931351</td>\n",
       "      <td>16</td>\n",
       "      <td>10171</td>\n",
       "      <td>0.004611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>workclass</td>\n",
       "      <td>1.647977</td>\n",
       "      <td>9</td>\n",
       "      <td>14308</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationship</td>\n",
       "      <td>2.154424</td>\n",
       "      <td>6</td>\n",
       "      <td>15724</td>\n",
       "      <td>0.000822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital-status</td>\n",
       "      <td>1.833649</td>\n",
       "      <td>7</td>\n",
       "      <td>16207</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>race</td>\n",
       "      <td>0.798741</td>\n",
       "      <td>5</td>\n",
       "      <td>15774</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.915736</td>\n",
       "      <td>2</td>\n",
       "      <td>16726</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>salary-class</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>2</td>\n",
       "      <td>16250</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Column  Shannon Entropy  Unique Values  \\\n",
       "5             age         5.683324             73   \n",
       "4      occupation         3.516903             15   \n",
       "7       education         2.931351             16   \n",
       "6       workclass         1.647977              9   \n",
       "3    relationship         2.154424              6   \n",
       "2  marital-status         1.833649              7   \n",
       "1            race         0.798741              5   \n",
       "0             sex         0.915736              2   \n",
       "8    salary-class         0.796384              2   \n",
       "\n",
       "   Unique Rows After Excluding Column  Contribution Score  \n",
       "5                                4672            0.088802  \n",
       "4                               10411            0.005067  \n",
       "7                               10171            0.004611  \n",
       "6                               14308            0.001037  \n",
       "3                               15724            0.000822  \n",
       "2                               16207            0.000792  \n",
       "1                               15774            0.000253  \n",
       "0                               16726            0.000109  \n",
       "8                               16250            0.000098  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Total number of rows (adjusted for the subset of data)\n",
    "def get_total_rows(df):\n",
    "    return len(df)\n",
    "\n",
    "def calculate_shannon_entropy(column):\n",
    "    # Calculate Shannon entropy for the column\n",
    "    value_counts = column.value_counts(normalize=True)\n",
    "    return entropy(value_counts, base=2)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_entropy(entropy_value, unique_values_count):\n",
    "    # Normalize entropy value\n",
    "    return entropy_value / unique_values_count\n",
    "\n",
    "def count_unique_rows(df):\n",
    "    # Count occurrences of each row\n",
    "    value_counts = df.value_counts()\n",
    "    # Count rows that only occur once\n",
    "    unique_rows_count = len(value_counts[value_counts == 1])\n",
    "    return unique_rows_count\n",
    "\n",
    "def calculate_unique_rows_excluding_column(df, column_name):\n",
    "    # Exclude the specified column\n",
    "    df_reduced = df.drop(columns=[column_name])\n",
    "    # Calculate unique rows in the reduced DataFrame\n",
    "    return count_unique_rows(df_reduced)\n",
    "\n",
    "def calculate_contribution_score(df, column_name):\n",
    "    column = df[column_name]\n",
    "    unique_values_count = column.nunique()\n",
    "    unique_rows_count_excluding_column = calculate_unique_rows_excluding_column(df, column_name)\n",
    "\n",
    "    # Calculate Shannon entropy, Gini-Simpson Index, and Effective Number of Classes\n",
    "    shannon_entropy_value = calculate_shannon_entropy(column)\n",
    "   \n",
    "\n",
    "    normalized_shannon_entropy_value = normalize_entropy(shannon_entropy_value, unique_values_count)\n",
    "    \n",
    "    # Contribution score using Shannon entropy\n",
    "    contribution_score_shannon = (shannon_entropy_value * unique_values_count) / unique_rows_count_excluding_column\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'Shannon Entropy': shannon_entropy_value,\n",
    "        'Unique Values': unique_values_count,\n",
    "        'Unique Rows After Excluding Column': unique_rows_count_excluding_column,\n",
    "         #'Normalized Shannon Entropy': normalized_shannon_entropy_value,\n",
    "        'Contribution Score': contribution_score_shannon,\n",
    "    }\n",
    "\n",
    "\n",
    "# Select specific columns\n",
    "selected_columns = ['sex', 'race', 'marital-status', 'relationship', 'occupation', 'age', 'workclass', 'education','salary-class']\n",
    "data_subset = data[selected_columns]\n",
    "\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "\n",
    "# Calculate contribution score using Shannon entropy, Gini-Simpson Index, and Effective Number of Classes\n",
    "for col in selected_columns:\n",
    "    result = calculate_contribution_score(data_subset, col)\n",
    "    results.append({\n",
    "        'Column': col,\n",
    "        **result\n",
    "    })\n",
    "    \n",
    "\n",
    "# Convert results to DataFrame for better readability\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Sort results by Contribution Score for Effective Number of Classes\n",
    "results_df = results_df.sort_values(by='Contribution Score', ascending=False)\n",
    "\n",
    "\n",
    "# Output the results\n",
    "print(len(data))\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contribution_score_shannon = (shannon_entropy_value * unique_values_count) / unique_rows_count_excluding_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By multiplying the entropy with the unique values for the given column we add the weight of having more unique values\n",
    "In the same manner, by dividing my the total number of unique rows after potentially excluding the column we make sure to add the \n",
    "importance of how much the column contributes to the overall unique rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023914401197604792"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.798741 * 5 / 16700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010966898203592814"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.915736 * 2 / 16700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Diversity Measurement: Shannon entropy quantifies how varied or uncertain the values are within a column. Columns with higher entropy have a more even distribution of values, indicating greater diversity.\n",
    "Implication: If a column has high entropy, it means that the values in this column are not clustered around a few categories but are spread out across many categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information Measure: Entropy is a measure of the amount of information or surprise associated with a random variable. Higher entropy means the column contains more information because it’s less predictable and more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let say we wanna evaluate more column together and not against eachother..then we would need to first find the \n",
    "total unique values for all the column so it could be C1 UV * C2 UV * C3 UV however this gives us the max and not the\n",
    "real view so first we have to compute it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For example\n",
    "Sex, race, relationship, workclass = 2 * 5 * 6 * 9  = 540 \n",
    "but we might not neccesarily reach this maximum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_column = data[['sex', 'race', 'relationship', 'workclass']].astype(str).agg('-'.join, axis=1)\n",
    "unique_rows_count = combined_column.nunique()\n",
    "unique_rows_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['sex', 'race', 'relationship', 'workclass','occupation']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>relationship</th>\n",
       "      <th>workclass</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Adm-clerical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Exec-managerial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Private</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Private</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Private</td>\n",
       "      <td>Prof-specialty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Private</td>\n",
       "      <td>Tech-support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Private</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Private</td>\n",
       "      <td>Adm-clerical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Private</td>\n",
       "      <td>Adm-clerical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Exec-managerial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sex    race    relationship          workclass          occupation\n",
       "0         Male   White   Not-in-family          State-gov        Adm-clerical\n",
       "1         Male   White         Husband   Self-emp-not-inc     Exec-managerial\n",
       "2         Male   White   Not-in-family            Private   Handlers-cleaners\n",
       "3         Male   Black         Husband            Private   Handlers-cleaners\n",
       "4       Female   Black            Wife            Private      Prof-specialty\n",
       "...        ...     ...             ...                ...                 ...\n",
       "32556   Female   White            Wife            Private        Tech-support\n",
       "32557     Male   White         Husband            Private   Machine-op-inspct\n",
       "32558   Female   White       Unmarried            Private        Adm-clerical\n",
       "32559     Male   White       Own-child            Private        Adm-clerical\n",
       "32560   Female   White            Wife       Self-emp-inc     Exec-managerial\n",
       "\n",
       "[32561 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-06dd1d5ef73a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Analyze all column combinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_column_combinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-159-06dd1d5ef73a>\u001b[0m in \u001b[0;36manalyze_column_combinations\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Parallel processing for handling all combinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_combination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_combinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def calculate_unique_rows(data, column_names):\n",
    "    # Combine columns into a single string column\n",
    "    combined_column = data[column_names].astype(str).agg('-'.join, axis=1)\n",
    "    # Return the number of unique rows in this combined column\n",
    "    return combined_column.nunique()\n",
    "\n",
    "def calculate_max_unique_rows(data, column_names):\n",
    "    # Calculate the maximum possible number of unique rows\n",
    "    return pd.Series([data[col].nunique() for col in column_names]).prod()\n",
    "\n",
    "def process_combination(data, column_names):\n",
    "    # Compute unique rows count and maximum unique rows for the given combination\n",
    "    unique_rows_count = calculate_unique_rows(data, column_names)\n",
    "    max_unique_rows = calculate_max_unique_rows(data, column_names)\n",
    "    return {\n",
    "        'Column Combination': ', '.join(column_names),\n",
    "        'Unique Rows Count': unique_rows_count,\n",
    "        'Max Unique Rows': max_unique_rows,\n",
    "        'Ratio': unique_rows_count / max_unique_rows\n",
    "    }\n",
    "\n",
    "def analyze_column_combinations(data):\n",
    "    columns = data.columns.tolist()\n",
    "    all_combinations = [list(subset) for r in range(1, len(columns) + 1) for subset in combinations(columns, r)]\n",
    "    \n",
    "    # Parallel processing for handling all combinations\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_combination)(data, subset) for subset in all_combinations)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "# Analyze all column combinations\n",
    "results_df = analyze_column_combinations(data)\n",
    "\n",
    "# Display results\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
